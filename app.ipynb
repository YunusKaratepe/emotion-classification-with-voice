{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_dict = {\n",
    "    0: 'Neutral',\n",
    "    1: 'Calm',\n",
    "    2: 'Happy',\n",
    "    3: 'Sad',\n",
    "    4: 'Angry',\n",
    "    5: 'Fearful',\n",
    "    6: 'Disgusted',\n",
    "    7: 'Surprised'\n",
    "}\n",
    "\n",
    "def create_spectrogram(audio_file, spectrogram_duration, order: int, spec_type: str):\n",
    "    voice, sr = librosa.load(audio_file)\n",
    "    after_stft = librosa.stft(voice, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        after_stft_i = after_stft[:,i*spectrogram_duration:(i+1)*spectrogram_duration]\n",
    "        if len(after_stft_i[1]) == 0:\n",
    "            break\n",
    "        abs_stft_result = np.abs(after_stft_i) ** 2\n",
    "        log_stft_result = librosa.power_to_db(abs_stft_result)\n",
    "        if order != 0:\n",
    "            log_stft_delta = librosa.feature.delta(log_stft_result, order)\n",
    "            plot_spectrogram(i, log_stft_delta, sr, HOP_LENGTH, y_axis=spec_type)\n",
    "        plot_spectrogram(i, log_stft_result, sr, HOP_LENGTH, y_axis=spec_type)\n",
    "        \n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "def plot_spectrogram(index, Y, sr, hop_length, y_axis=\"log\"):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.axis('off')\n",
    "    librosa.display.specshow(Y,\n",
    "                             sr=sr,\n",
    "                             hop_length=hop_length,\n",
    "                             y_axis=y_axis)\n",
    "\n",
    "    plt.savefig(f\"./spectrogram{index}.png\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    \n",
    "def predict_emotion(index, cnn_model_path, spec_type='log', test_path=\"none\"):\n",
    "\n",
    "    if not os.path.exists(f\"./spectrogram{index}.png\"):\n",
    "        print(\"Please first run Create Spectrogram section.\")\n",
    "        return\n",
    "    if not os.path.exists(cnn_model_path):\n",
    "        print(\"Model path does not exists.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    cnn = load_model(cnn_model_path)\n",
    "\n",
    "    #spec = cv2.imread(\"./spectrogram.png\")\n",
    "    # spec = cv2.imread(test_path)\n",
    "\n",
    "    # spec = cv2.resize(spec, (128, 128))\n",
    "\n",
    "    if test_path != \"none\":\n",
    "        spec = tf.keras.preprocessing.image.load_img(test_path, target_size=(128, 128))\n",
    "\n",
    "    else:\n",
    "        spec = tf.keras.preprocessing.image.load_img(f\"./spectrogram{index}.png\", target_size=(128, 128))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    spec = np.reshape(spec, [1, 128, 128, 3])\n",
    "\n",
    "\n",
    "    classes = cnn.predict(spec)\n",
    "    \n",
    "    return emotions_dict[list(classes[0]).index(max(list(classes[0])))]\n",
    "\n",
    "\n",
    "def predict_emotion_ml(index, cnn_model_path, spec_type='log', seed=10, ml_algorithm='SVC_Polynomial_Kernel', test_path=\"none\"):\n",
    "\n",
    "    ml_model_path = \"./models/ml_models0/seed\" + str(seed) + \"/\"  + ml_algorithm + \".sav\"\n",
    "    if not os.path.exists(ml_model_path):\n",
    "        print(\"ML-Model type is not valid.\")\n",
    "        return\n",
    "    if not os.path.exists(f\"./spectrogram{index}.png\"):\n",
    "        print(\"Please first run Create Spectrogram section.\")\n",
    "        return\n",
    "    if not os.path.exists(cnn_model_path):\n",
    "        print(\"Model path does not exists.\")\n",
    "        return\n",
    "\n",
    "    cnn = load_model(cnn_model_path)\n",
    "    \n",
    "    \n",
    "    if test_path != \"none\":\n",
    "        spec = tf.keras.preprocessing.image.load_img(test_path, target_size=(128, 128))\n",
    "\n",
    "    else:\n",
    "        spec = tf.keras.preprocessing.image.load_img(f\"./spectrogram{index}.png\", target_size=(128, 128))\n",
    "\n",
    "\n",
    "    spec = np.reshape(spec, [1, 128, 128, 3])\n",
    "    \n",
    "    outputLayer = cnn.layers[-5]\n",
    "    intermediate_layer_model = Model(inputs=cnn.input,\n",
    "                                    outputs=outputLayer.output)\n",
    "\n",
    "    intermediate_output = intermediate_layer_model.predict(spec)\n",
    "\n",
    "\n",
    "    ml_model = pickle.load(open(ml_model_path, 'rb'))\n",
    "\n",
    "    # ---------------------------------------------- problematik\n",
    "\n",
    "    \n",
    "    # ml_output = ml_model.predict_proba(lst)\n",
    "    # ml_list = list(ml_output)\n",
    "    \n",
    "    \n",
    "    for i in range(9):\n",
    "        result = ml_model.score(intermediate_output, [i])\n",
    "        # print(str(int(result)), end=\"\\t\")\n",
    "        if result == 1:\n",
    "            return emotions_dict[int(i)]\n",
    "    \n",
    "    # emotions_dict[ml_list.index(max(ml_list))] \n",
    "    \n",
    "def clear_spectrograms(path_to_spectrograms):\n",
    "    files = os.listdir(path_to_spectrograms)\n",
    "    for f in files:\n",
    "        if f.startswith('spectrogram') and f.endswith('.png'):\n",
    "            os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can play with these.\n",
    "spec_type = 'log'\n",
    "seed=10\n",
    "order = 0\n",
    "cnn_model_path = \"./models/cnn_models_epoch50/seed\" + str(seed) + \"/logSpecAugment.h5\"\n",
    "\n",
    "# Not recommended to change these.\n",
    "FRAME_SIZE = 2048\n",
    "HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = './audios/happy.mp3'\n",
    "ipd.Audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_spectrogram(audio_file, order=order, spec_type=spec_type) # ignore warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "predict_emotion(cnn_model_path=cnn_model_path, spec_type=spec_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN + ML\n",
    "print(predict_emotion_ml(cnn_model_path=cnn_model_path, spec_type=spec_type, seed=seed, ml_algorithm='SVC_Polynomial_Kernel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "audio_file = './audios/calm.mp3'\n",
    "# audio_file = './data/15_03_16.wav'\n",
    "\n",
    "cnn_predicts = []\n",
    "# svc_poly_predicts = []\n",
    "linearSVC_predicts = []\n",
    "linear_discriminant_predicts = []\n",
    "logistic_regression_predicts = []\n",
    "\n",
    "max_i = create_spectrogram(audio_file, spectrogram_duration=140, order=order, spec_type=spec_type) # ignore warning\n",
    "\n",
    "for i in range(max_i):\n",
    "    for s in [10, 50, 100]:\n",
    "        cnn_model_path = \"./models/cnn_models_epoch50/seed\" + str(s) + \"/logSpecAugment.h5\"\n",
    "        \n",
    "        cnn_predicts.append(predict_emotion(i, cnn_model_path=cnn_model_path, spec_type=spec_type))\n",
    "        # svc_poly_predicts.append(predict_emotion_ml(i, cnn_model_path=cnn_model_path, spec_type=spec_type, seed=seed, ml_algorithm='SVC_Polynomial_Kernel'))\n",
    "        linearSVC_predicts.append(predict_emotion_ml(i, cnn_model_path=cnn_model_path, spec_type=spec_type, seed=seed, ml_algorithm='LinearSVC'))\n",
    "        linear_discriminant_predicts.append(predict_emotion_ml(i, cnn_model_path=cnn_model_path, spec_type=spec_type, seed=seed, ml_algorithm='LinearDiscriminantAnalysis'))\n",
    "        logistic_regression_predicts.append(predict_emotion_ml(i, cnn_model_path=cnn_model_path, spec_type=spec_type, seed=seed, ml_algorithm='LogisticRegression'))\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "all_predicts = cnn_predicts + linearSVC_predicts + linear_discriminant_predicts + logistic_regression_predicts\n",
    "most_commons = Counter(all_predicts).most_common(2)\n",
    "print('Classified with voting:', most_commons)\n",
    "clear_spectrograms(path_to_spectrograms='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn_predicts)\n",
    "# print(svc_poly_predicts)\n",
    "print(linearSVC_predicts)\n",
    "print(linear_discriminant_predicts)\n",
    "print(logistic_regression_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2675592439886072215c5492b56ef91d6259dc08377ceafc1fad216e79bf788"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}